# Batchata

Batch processing library for AI models with cost tracking, state persistence, and parallel execution.

## Core API

```python
from batchata import Batch

# Create batch with state persistence
batch = Batch(state_file="./state.json", results_dir="./output", max_concurrent=10)
    .defaults(model="claude-3-sonnet", temperature=0.7)
    .add_cost_limit(usd=50.0)
    .on_progress(lambda stats: print(f"Progress: {stats['completed']}/{stats['total']}"))

# Add jobs
batch.add_job(messages=[{"role": "user", "content": "Text"}])
batch.add_job(file="doc.pdf", prompt="Summarize", response_model=MyModel)

# Execute
run = batch.run(wait=True)
results = run.results()  # Dict[job_id, JobResult]
```

## Key Features

- Native batch processing (50% cost savings)
- Automatic state persistence and recovery
- Cost tracking with limits
- Parallel execution
- Structured output with Pydantic
- Citation extraction

## Classes

- `Batch`: Configuration builder
- `BatchRun`: Execution manager
- `Job`: Single AI task configuration
- `JobResult`: Task result with metadata

## State Management

State automatically saved to `state_file` for recovery from interruptions. Results saved individually to `results_dir`.